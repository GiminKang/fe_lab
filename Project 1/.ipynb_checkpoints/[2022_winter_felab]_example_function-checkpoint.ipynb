{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d64943cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import karateclub\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from networkx.algorithms import approximation\n",
    "from networkx.algorithms import bipartite\n",
    "from networkx.algorithms.threshold import is_threshold_graph\n",
    "from networkx.algorithms import tournament\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8f3b3772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nudge(pos, x_shift, y_shift):\n",
    "    return {n:(x + x_shift, y + y_shift) for n,(x,y) in pos.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1818c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2ae1d7",
   "metadata": {},
   "source": [
    "\n",
    "# Network-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93813539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undirected_network_level(G):\n",
    "    \n",
    "    measure_list = []\n",
    "\n",
    "    try:\n",
    "        m1 = nx.node_connectivity(G)\n",
    "    except:\n",
    "        m1 = 0\n",
    "    measure_list.append(m1)\n",
    "    \n",
    "    try:\n",
    "        m2 = nx.approximation.treewidth_min_degree(G)[0]\n",
    "    except:\n",
    "        m2 = 0\n",
    "    measure_list.append(m2)\n",
    "    \n",
    "    try:\n",
    "        m3 = nx.approximation.treewidth_min_fill_in(G)[0]\n",
    "    except:\n",
    "        m3 = 0\n",
    "    measure_list.append(m3)\n",
    "\n",
    "    try:\n",
    "        m4 = nx.degree_assortativity_coefficient(G)\n",
    "        \n",
    "    except:\n",
    "        m4 = 0\n",
    "    measure_list.append(m4)\n",
    "    \n",
    "    try:\n",
    "        m5 = int(nx.is_at_free(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m5 = 0\n",
    "    measure_list.append(m5)\n",
    "    \n",
    "    try:\n",
    "        m6 = nx.density(G)\n",
    "        \n",
    "    except:\n",
    "        m6 = 0\n",
    "    measure_list.append(m6)\n",
    "    \n",
    "    try:\n",
    "        m7 = int(nx.is_bipartite(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m7 = 0\n",
    "    measure_list.append(m7)\n",
    "\n",
    "    try:\n",
    "        m8 = nx.bipartite.spectral_bipartivity(G)\n",
    "        \n",
    "    except:\n",
    "        m8 = 0\n",
    "    measure_list.append(m8)\n",
    "    \n",
    "    try:\n",
    "        m9 = nx.estrada_index(G)\n",
    "        \n",
    "    except:\n",
    "        m9 = 0\n",
    "    measure_list.append(m9)\n",
    "    \n",
    "    try:\n",
    "        m10 = nx.global_reaching_centrality(G)\n",
    "        \n",
    "    except:\n",
    "        m10 = 0\n",
    "    measure_list.append(m10)\n",
    "    \n",
    "    try:\n",
    "        m11 = int(nx.is_chordal(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m11 = 0\n",
    "    measure_list.append(m11)    \n",
    "    \n",
    "    try:\n",
    "        m12 = nx.transitivity(G)\n",
    "        \n",
    "    except:\n",
    "        m12 = 0\n",
    "    measure_list.append(m12)  \n",
    "    \n",
    "    try:\n",
    "        m13 = nx.average_clustering(G)\n",
    "        \n",
    "    except:\n",
    "        m13 = 0\n",
    "    measure_list.append(m13)\n",
    "    \n",
    "    try:\n",
    "        m14 = int(nx.is_connected(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m14 = 0\n",
    "    measure_list.append(m14)  \n",
    "    \n",
    "    try:\n",
    "        m15 = nx.number_connected_components(G)\n",
    "        \n",
    "    except:\n",
    "        m15 = 0\n",
    "    measure_list.append(m15)\n",
    "    \n",
    "    try:\n",
    "        m16 = nx.node_connectivity(G)\n",
    "        \n",
    "    except:\n",
    "        m16 = 0\n",
    "    measure_list.append(m16)\n",
    "    \n",
    "    try:\n",
    "        m17 = nx.edge_connectivity(G)\n",
    "        \n",
    "    except:\n",
    "        m17 = 0\n",
    "    measure_list.append(m17)\n",
    "    \n",
    "    try:\n",
    "        m18 = nx.diameter(G)\n",
    "        \n",
    "    except:\n",
    "        m18 = 0\n",
    "    measure_list.append(m18)\n",
    "    \n",
    "    try:\n",
    "        m19 = nx.radius(G)\n",
    "        \n",
    "    except:\n",
    "        m19 = 0\n",
    "    measure_list.append(m19)\n",
    "    \n",
    "    try:\n",
    "        m20 = int(nx.is_distance_regular(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m20 = 0\n",
    "    measure_list.append(m20)\n",
    "    \n",
    "    try:\n",
    "        m21 = int(nx.is_strongly_regular(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m21 = 0\n",
    "    measure_list.append(m21)\n",
    "    \n",
    "    try:\n",
    "        m22 = nx.local_efficiency(G)\n",
    "        \n",
    "    except:\n",
    "        m22 = 0\n",
    "    measure_list.append(m22)\n",
    "    \n",
    "    try:\n",
    "        m23 = nx.global_efficiency(G)\n",
    "        \n",
    "    except:\n",
    "        m23 = 0\n",
    "    measure_list.append(m23)\n",
    "    \n",
    "    try:\n",
    "        m24 = int(nx.is_eulerian(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m24 = 0\n",
    "    measure_list.append(m24)\n",
    "    \n",
    "    try:\n",
    "        m25 = int(nx.number_of_isolates(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m25 = 0\n",
    "    measure_list.append(m25)\n",
    "    \n",
    "    try:\n",
    "        m26 = nx.reciprocity(G)\n",
    "        \n",
    "    except:\n",
    "        m26 = 0\n",
    "    measure_list.append(m26)\n",
    "    \n",
    "    try:\n",
    "        m27 = nx.overall_reciprocity(G)\n",
    "        \n",
    "    except:\n",
    "        m27 = 0\n",
    "    measure_list.append(m27)\n",
    "    \n",
    "    try:\n",
    "        m28 = int(nx.is_regular(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m28 = 0\n",
    "    measure_list.append(m28)\n",
    "    \n",
    "    try:\n",
    "        m29 = nx.average_shortest_path_length(G)\n",
    "        \n",
    "    except:\n",
    "        m29 = 0\n",
    "    measure_list.append(m29)\n",
    "    \n",
    "    try:\n",
    "        m30 = int(nx.negative_edge_cycle(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m30 = 0\n",
    "    measure_list.append(m30)\n",
    "    \n",
    "    try:\n",
    "        m31 = nx.s_metric(G, normalized = False)\n",
    "        \n",
    "    except:\n",
    "        m31 = 0\n",
    "    measure_list.append(m31)\n",
    "    \n",
    "    try:\n",
    "        m32 = int(nx.is_tree(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m32 = 0\n",
    "    measure_list.append(m32)\n",
    "    \n",
    "    try:\n",
    "        m33 = int(nx.is_forest(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m33 = 0\n",
    "    measure_list.append(m33)\n",
    "    \n",
    "    try:\n",
    "        m34 = int(nx.is_triad(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m34 = 0\n",
    "    measure_list.append(m34)\n",
    "    \n",
    "    try:\n",
    "        m35 = nx.wiener_index(G)\n",
    "        \n",
    "    except:\n",
    "        m35 = 0\n",
    "    measure_list.append(m35)\n",
    "    \n",
    "        \n",
    "    try:\n",
    "        m36 = nx.stoer_wagner(G)[0]\n",
    "        \n",
    "    except:\n",
    "        m36 = 0\n",
    "    measure_list.append(m36)\n",
    "\n",
    "    final_df = pd.DataFrame(measure_list).T\n",
    "    final_df.columns = ['node_connectivity',   \n",
    "'treewidth_min_degree',\n",
    "'treewidth_min_fill',\n",
    "'degree_assortativity_coefficient',\n",
    "'is_asteriodal_triple_free',\n",
    "'density',\\\n",
    "'is_bipartite',\\\n",
    "'spectral_bipartivity',\\\n",
    "'estrada_index',\\\n",
    "'global_reaching_centrality',\\\n",
    "'is_chordal',\\\n",
    "'transitivity',\\\n",
    "'average_clustering',\\\n",
    "'is_connected',\\\n",
    "'number_connected_components',\\\n",
    "'node_connectivity',\\\n",
    "'edge_connectivity',\\\n",
    "'diameter',\\\n",
    "'radius',\\\n",
    "'is_distance_regular',\\\n",
    "'is_strongly_regular',\\\n",
    "'local_efficiency',\\\n",
    "'global_efficiency',\\\n",
    "'is_eulerian',\\\n",
    "'number_of_isolates',\\\n",
    "'reciprocity',\\\n",
    "'overall_reciprocity',\\\n",
    "'is_regular',\\\n",
    "'average_shortest_path_length',\\\n",
    "'negative_edge_cycle',\\\n",
    "'s_metric',\\\n",
    "'is_tree',\\\n",
    "'is_forest',\\\n",
    "'is_triad',\\\n",
    "'wiener_index',\\\n",
    "'stoer_wagner']\n",
    "    final_df.index = ['Date']\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c87f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def directed_network_level(G):\n",
    "    \n",
    "    measure_list = []\n",
    "\n",
    "    try:\n",
    "        m1 = nx.node_connectivity(G)\n",
    "    except:\n",
    "        m1 = 0\n",
    "    measure_list.append(m1)\n",
    "    \n",
    "    try:\n",
    "        m2 = nx.degree_assortativity_coefficient(G)\n",
    "    except:\n",
    "        m2 = 0\n",
    "    measure_list.append(m2)\n",
    "\n",
    "    try:\n",
    "        m3 = nx.density(G)\n",
    "        \n",
    "    except:\n",
    "        m3 = 0\n",
    "    measure_list.append(m3)\n",
    "    \n",
    "    try:\n",
    "        m4 = int(nx.is_bipartite(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m4 = 0\n",
    "    measure_list.append(m4)\n",
    "\n",
    "    try:\n",
    "        m5 = nx.bipartite.spectral_bipartivity(G)\n",
    "        \n",
    "    except:\n",
    "        m5 = 0\n",
    "    measure_list.append(m5)\n",
    "    \n",
    "    try:\n",
    "        m6 = nx.global_reaching_centrality(G)\n",
    "        \n",
    "    except:\n",
    "        m6 = 0\n",
    "    measure_list.append(m6)   \n",
    "    \n",
    "    try:\n",
    "        m7 = nx.transitivity(G)\n",
    "        \n",
    "    except:\n",
    "        m7 = 0\n",
    "    measure_list.append(m7)  \n",
    "    \n",
    "    try:\n",
    "        m8 = nx.average_clustering(G)\n",
    "        \n",
    "    except:\n",
    "        m8 = 0\n",
    "    measure_list.append(m8)\n",
    "    \n",
    "    try:\n",
    "        m9 = int(nx.is_strongly_connected(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m9 = 0\n",
    "    measure_list.append(m9)  \n",
    "\n",
    "    try:\n",
    "        m10 = int(nx.is_weakly_connected(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m10 = 0\n",
    "    measure_list.append(m10)\n",
    "\n",
    "    try:\n",
    "        m11 = int(nx.is_attracting_component(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m11 = 0\n",
    "    measure_list.append(m11)\n",
    "    \n",
    "    try:\n",
    "        m12 = int(nx.is_semiconnected(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m12 = 0\n",
    "    measure_list.append(m12)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        m13 = nx.edge_connectivity(G)\n",
    "        \n",
    "    except:\n",
    "        m13 = 0\n",
    "    measure_list.append(m13)\n",
    "\n",
    "    try:\n",
    "        m14 = int(nx.is_directed_acyclic_graph(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m14 = 0\n",
    "    measure_list.append(m14)\n",
    "    \n",
    "    try:\n",
    "        m15 = int(nx.is_aperiodic(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m15 = 0\n",
    "    measure_list.append(m15)\n",
    "    \n",
    "    try:\n",
    "        m16 = nx.diameter(G)\n",
    "        \n",
    "    except:\n",
    "        m16 = 0\n",
    "    measure_list.append(m16)\n",
    "    \n",
    "    try:\n",
    "        m17 = nx.radius(G)\n",
    "        \n",
    "    except:\n",
    "        m17 = 0\n",
    "    measure_list.append(m17)\n",
    "    \n",
    "    try:\n",
    "        m18 = int(nx.is_distance_regular(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m18 = 0\n",
    "    measure_list.append(m18)\n",
    "    \n",
    "    try:\n",
    "        m20 = int(nx.is_strongly_regular(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m20 = 0\n",
    "    measure_list.append(m20)\n",
    "    \n",
    "    try:\n",
    "        m21 = int(nx.is_eulerian(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m21 = 0\n",
    "    measure_list.append(m21)\n",
    "    \n",
    "    try:\n",
    "        m22 = int(nx.number_of_isolates(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m22 = 0\n",
    "    measure_list.append(m22)\n",
    "    \n",
    "    try:\n",
    "        m24 = nx.overall_reciprocity(G)\n",
    "        \n",
    "    except:\n",
    "        m24 = 0\n",
    "    measure_list.append(m24)\n",
    "    \n",
    "    try:\n",
    "        m25 = int(nx.is_regular(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m25 = 0\n",
    "    measure_list.append(m25)\n",
    "    \n",
    "    try:\n",
    "        m26 = int(nx.negative_edge_cycle(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m26 = 0\n",
    "    measure_list.append(m26)\n",
    "    \n",
    "    try:\n",
    "        m27 = nx.s_metric(G, normalized = False)\n",
    "        \n",
    "    except:\n",
    "        m27 = 0\n",
    "    measure_list.append(m27)\n",
    "\n",
    "    try:\n",
    "        m28 = nx.int(is_threshold_graph(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m28 = 0\n",
    "    measure_list.append(m28)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        m29 = int(tournament.is_tournament(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m29 = 0\n",
    "    measure_list.append(m29)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        m32 = int(nx.is_arborescence(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m32 = 0\n",
    "    measure_list.append(m32)\n",
    "    \n",
    "    try:\n",
    "        m33 = int(nx.is_branching(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m33 = 0\n",
    "    measure_list.append(m33)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        m34 = int(nx.is_triad(G) == True)\n",
    "        \n",
    "    except:\n",
    "        m34 = 0\n",
    "    measure_list.append(m34)\n",
    "    \n",
    "    try:\n",
    "        m35 = nx.wiener_index(G)\n",
    "        \n",
    "    except:\n",
    "        m35 = 0\n",
    "    measure_list.append(m35)\n",
    "    \n",
    "    try:\n",
    "        m36 = nx.trophic_incoherence_parameter(G)\n",
    "\n",
    "    except:\n",
    "        m36 = 0\n",
    "    measure_list.append(m36)\n",
    "\n",
    "    final_df = pd.DataFrame(measure_list).T\n",
    "    final_df.columns = ['node_connectivity',\n",
    "'degree_assortativity_coefficient',\n",
    "'density',\n",
    "'is_bipartite',\n",
    "'spectral_bipartivity',\n",
    "'global_reaching_centrality',\n",
    "'transitivity',\n",
    "'average_clustering',\n",
    "'is_strongly_connected',\n",
    "'is_weakly_connected',\n",
    "'is_attracting_component',\n",
    "'is_semiconnected',\n",
    "'edge_connectivity',\n",
    "'is_directed_acyclic_graph',\n",
    "'is_aperiodic',\n",
    "'diameter',\n",
    "'radius',\n",
    "'is_distance_regular',\n",
    "'is_strongly_regular',\n",
    "'is_eulerian',\n",
    "'number_of_isolates',\n",
    "'overall_reciprocity',\n",
    "'is_regular',\n",
    "'negative_edge_cycle',\n",
    "'s_metric',\n",
    "'is_threshold_graph',\n",
    "'is_tournament',\n",
    "'is_arborescence',\n",
    "'is_branching',\n",
    "'is_triad',\n",
    "'wiener_index', \n",
    "'trophic_incoherence_parameter']\n",
    "    final_df.index = ['Date']\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31fde72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undirected_node_level(G):\n",
    "\n",
    "    try:\n",
    "        m1 = pd.DataFrame.from_dict([nx.average_neighbor_degree(G)]).T\n",
    "    except:\n",
    "        m1 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m1.index = list(G.nodes)\n",
    "    m1.sort_index()\n",
    "\n",
    "    try:\n",
    "        m2 = pd.DataFrame.from_dict([bipartite.node_redundancy(G)]).T\n",
    "    except:\n",
    "        m2 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m2.index = list(G.nodes)\n",
    "    m2.sort_index()\n",
    "\n",
    "    try:\n",
    "        m3 = pd.DataFrame.from_dict([nx.degree_centrality(G)]).T\n",
    "    except:\n",
    "        m3 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m3.index = list(G.nodes)        \n",
    "    m3.sort_index()\n",
    "    try:\n",
    "        m4 = pd.DataFrame.from_dict([nx.eigenvector_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m4 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m4.index = list(G.nodes)\n",
    "    m4.sort_index()\n",
    "    try:\n",
    "        m5 = pd.DataFrame.from_dict([nx.closeness_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m5 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m5.index = list(G.nodes)\n",
    "    m5.sort_index()\n",
    "    try:\n",
    "        m6 = pd.DataFrame.from_dict([nx.current_flow_closeness_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m6 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m6.index = list(G.nodes)\n",
    "    m6.sort_index()\n",
    "    try:\n",
    "        m7 = pd.DataFrame.from_dict([nx.information_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m7 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m7.index = list(G.nodes)\n",
    "    m7.sort_index()\n",
    "    try:\n",
    "        m8 = pd.DataFrame.from_dict([nx.betweenness_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m8 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m8.index = list(G.nodes)\n",
    "    m8.sort_index()\n",
    "    try:\n",
    "        m9 = pd.DataFrame.from_dict([nx.current_flow_betweenness_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m9 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m9.index = list(G.nodes)\n",
    "    m9.sort_index()\n",
    "    try:\n",
    "        m10 = pd.DataFrame.from_dict([nx.approximate_current_flow_betweenness_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m10 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m10.index = list(G.nodes)\n",
    "    m10.sort_index()\n",
    "    try:\n",
    "        m11 = pd.DataFrame.from_dict([nx.communicability_betweenness_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m11 = pd.DataFrame([0 for i in range(len(G.nodes))]) \n",
    "        m11.index = list(G.nodes)\n",
    "    m11.sort_index()\n",
    "    try:\n",
    "        m12 = pd.DataFrame.from_dict([nx.subgraph_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m12 = pd.DataFrame([0 for i in range(len(G.nodes))])  \n",
    "        m12.index = list(G.nodes)\n",
    "    m12.sort_index()\n",
    "    try:\n",
    "        m13 = pd.DataFrame.from_dict([nx.harmonic_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m13 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m13.index = list(G.nodes)\n",
    "    m13.sort_index()\n",
    "    try:\n",
    "        m14 = pd.DataFrame.from_dict([nx.second_order_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m14 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m14.index = list(G.nodes)\n",
    "    m14.sort_index()\n",
    "    \n",
    "    vote = []\n",
    "\n",
    "    try:\n",
    "        for column in list(G.nodes):\n",
    "            if column in list(nx.voterank(G)):\n",
    "\n",
    "                vote.append(1)\n",
    "            else:\n",
    "                vote.append(0)\n",
    "\n",
    "        m15 = pd.DataFrame(vote)\n",
    "        m15.index = list(G.nodes)\n",
    "\n",
    "\n",
    "    except:\n",
    "        m15 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m15.index = list(G.nodes)\n",
    "    m15.sort_index()\n",
    "    try:\n",
    "        m16 = pd.DataFrame.from_dict([nx.number_of_cliques(G)]).T\n",
    "\n",
    "    except:\n",
    "        m16 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m16.index = list(G.nodes)\n",
    "    m16.sort_index()\n",
    "\n",
    "    try:\n",
    "        m17 = pd.DataFrame.from_dict([nx.triangles(G)]).T\n",
    "\n",
    "    except:\n",
    "        m17 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m17.index = list(G.nodes)\n",
    "        m17.sort_index()\n",
    "        \n",
    "    try:\n",
    "        m18 = pd.DataFrame.from_dict([nx.clustering(G)]).T\n",
    "\n",
    "    except:\n",
    "        m18 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m18.index = list(G.nodes)\n",
    "    m18.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m19 = pd.DataFrame.from_dict([nx.square_clustering(G)]).T\n",
    "\n",
    "    except:\n",
    "        m19 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m19.index = list(G.nodes)\n",
    "    m19.sort_index()\n",
    "\n",
    "    try:\n",
    "        m20 = pd.DataFrame.from_dict([nx.eccentricity(G)]).T\n",
    "\n",
    "    except:\n",
    "        m20 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m20.index = list(G.nodes)\n",
    "    \n",
    "    m20.sort_index()\n",
    "\n",
    "    try:\n",
    "        m21 = pd.DataFrame.from_dict([nx.pagerank(G)]).T\n",
    "\n",
    "    except:\n",
    "        m21 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m21.index = list(G.nodes)\n",
    "    \n",
    "    m21.sort_index()\n",
    "\n",
    "    try:\n",
    "        m22 = pd.DataFrame.from_dict([nx.hits(G)[0]]).T\n",
    "\n",
    "    except:\n",
    "        m22 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m22.index = list(G.nodes)\n",
    "    m22.sort_index()\n",
    "\n",
    "    try:\n",
    "        m23 = pd.DataFrame.from_dict([nx.hits(G)[1]]).T\n",
    "\n",
    "    except:\n",
    "        m23 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m23.index = list(G.nodes)\n",
    "    m23.sort_index()\n",
    "    try:\n",
    "        m24 = pd.DataFrame.from_dict([nx.constraint(G)]).T\n",
    "\n",
    "    except:\n",
    "        m24 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m24.index = list(G.nodes)\n",
    "    m24.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m25 = pd.DataFrame.from_dict([nx.effective_size(G)]).T\n",
    "\n",
    "    except:\n",
    "        m25 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m25.index = list(G.nodes)\n",
    "    m25.sort_index()\n",
    "\n",
    "    try:\n",
    "        m26 = pd.DataFrame.from_dict([nx.closeness_vitality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m26 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m26.index = list(G.nodes)\n",
    "    m26.sort_index()\n",
    "\n",
    "    try:\n",
    "        m27 = nx.chordal_graph_treewidth(G)\n",
    "        \n",
    "    except:\n",
    "        m27 = pd.DataFrame([np.nan for i in range(len(G.nodes))])\n",
    "        m27.index = list(G.nodes)\n",
    "    m27.sort_index()\n",
    "    \n",
    "    final_df = pd.concat([m1, m2, m3, m4, m5, m6, m7, m8, m9, m10, m11, m12, m13, m14, m15, m16, m17, m18, m19,\n",
    "                         m20, m21, m22, m23, m24, m25, m26, m27], axis = 1)\n",
    "    final_df.columns = ['average_neighbor_degree',\n",
    "    'node_redundancy',\n",
    "    'degree_centrality',\n",
    "    'eigenvector_centrality',\n",
    "    'closeness_centrality',\n",
    "    'current_flow_closeness_centrality',\n",
    "    'information_centrality',\n",
    "    'betweenness_centrality',\n",
    "    'current_flow_betweenness_centrality',\n",
    "    'approximate_current_flow_betweenness_centrality',\n",
    "    'communicability_betweenness_centrality',\n",
    "    'subgraph_centrality',\n",
    "    'harmonic_centrality',\n",
    "    'second_order_centrality',\n",
    "    'voterank_importance',\n",
    "    'number_of_cliques',\n",
    "    'triangles',\n",
    "    'clustering',\n",
    "    'square_clustering',\n",
    "    'eccentricity',\n",
    "    'pagerank',\n",
    "    'hits_hub',\n",
    "    'hits_authority',\n",
    "    'constraint',\n",
    "    'effective_size',\n",
    "    'closeness_vitality',\n",
    "    'chordal_graph_treewidth']\n",
    "    \n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "edbd09de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def directed_node_level(G):\n",
    "\n",
    "    try:\n",
    "        m1 = pd.DataFrame.from_dict([nx.average_neighbor_degree(G)]).T\n",
    "    except:\n",
    "        m1 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m1.index = list(G.nodes)\n",
    "    m1.sort_index()\n",
    "\n",
    "    try:\n",
    "        m2 = pd.DataFrame.from_dict([bipartite.node_redundancy(G)]).T\n",
    "    except:\n",
    "        m2 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m2.index = list(G.nodes)\n",
    "    m2.sort_index()\n",
    "\n",
    "    try:\n",
    "        m3 = pd.DataFrame.from_dict([nx.degree_centrality(G)]).T\n",
    "    except:\n",
    "        m3 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m3.index = list(G.nodes)\n",
    "    m3.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m4 = pd.DataFrame.from_dict([nx.eigenvector_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m4 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m4.index = list(G.nodes)        \n",
    "    m4.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m5 = pd.DataFrame.from_dict([nx.closeness_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m5 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m5.index = list(G.nodes)\n",
    "    m5.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m6 = pd.DataFrame.from_dict([nx.current_flow_closeness_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m6 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m6.index = list(G.nodes)\n",
    "    m6.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m7 = pd.DataFrame.from_dict([nx.information_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m7 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m7.index = list(G.nodes)\n",
    "    m7.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m8 = pd.DataFrame.from_dict([nx.betweenness_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m8 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m8.index = list(G.nodes)\n",
    "    m8.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m9 = pd.DataFrame.from_dict([nx.current_flow_betweenness_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m9 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m9.index = list(G.nodes)    \n",
    "    m9.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m10 = pd.DataFrame.from_dict([nx.approximate_current_flow_betweenness_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m10 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m10.index = list(G.nodes)    \n",
    "    m10.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m11 = pd.DataFrame.from_dict([nx.communicability_betweenness_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m11 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m11.index = list(G.nodes)\n",
    "    m11.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m12 = pd.DataFrame.from_dict([nx.subgraph_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m12 = pd.DataFrame([0 for i in range(len(G.nodes))]) \n",
    "        m12.index = list(G.nodes)\n",
    "    m12.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m13 = pd.DataFrame.from_dict([nx.harmonic_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m13 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m13.index = list(G.nodes)\n",
    "    m13.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m14 = pd.DataFrame.from_dict([nx.second_order_centrality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m14 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m14.index = list(G.nodes)\n",
    "    m14.sort_index()\n",
    "    \n",
    "    vote = []\n",
    "\n",
    "    try:\n",
    "        for column in list(G.nodes):\n",
    "            if column in list(nx.voterank(G)):\n",
    "\n",
    "                vote.append(1)\n",
    "            else:\n",
    "                vote.append(0)\n",
    "\n",
    "        m15 = pd.DataFrame(vote)\n",
    "        m15.index = list(G.nodes)\n",
    "\n",
    "    except:\n",
    "        m15 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m15.index = list(G.nodes)\n",
    "    m15.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m16 = pd.DataFrame.from_dict([nx.number_of_cliques(G)]).T\n",
    "\n",
    "    except:\n",
    "        m16 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m16.index = list(G.nodes)\n",
    "    m16.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m17 = pd.DataFrame.from_dict([nx.triangles(G)]).T\n",
    "\n",
    "    except:\n",
    "        m17 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m17.index = list(G.nodes)\n",
    "    m17.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m18 = pd.DataFrame.from_dict([nx.clustering(G)]).T\n",
    "\n",
    "    except:\n",
    "        m18 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m18.index = list(G.nodes)\n",
    "    m18.sort_index()\n",
    "\n",
    "    try:\n",
    "        m19 = pd.DataFrame.from_dict([nx.square_clustering(G)]).T\n",
    "\n",
    "    except:\n",
    "        m19 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m19.index = list(G.nodes)\n",
    "    m19.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m20 = pd.DataFrame.from_dict([nx.eccentricity(G)]).T\n",
    "\n",
    "    except:\n",
    "        m20 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m20.index = list(G.nodes)\n",
    "    m20.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m21 = pd.DataFrame.from_dict([nx.pagerank(G)]).T\n",
    "\n",
    "    except:\n",
    "        m21 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m21.index = list(G.nodes)\n",
    "    m21.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m22 = pd.DataFrame.from_dict([nx.hits(G)[0]]).T\n",
    "\n",
    "    except:\n",
    "        m22 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m22.index = list(G.nodes)\n",
    "    m22.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m23 = pd.DataFrame.from_dict([nx.hits(G)[1]]).T\n",
    "\n",
    "    except:\n",
    "        m23 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m23.index = list(G.nodes)    \n",
    "    m23.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m24 = pd.DataFrame.from_dict([nx.constraint(G)]).T\n",
    "\n",
    "    except:\n",
    "        m24 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m24.index = list(G.nodes)\n",
    "    m24.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m25 = pd.DataFrame.from_dict([nx.effective_size(G)]).T\n",
    "\n",
    "    except:\n",
    "        m25 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m25.index = list(G.nodes)\n",
    "    m25.sort_index()\n",
    "\n",
    "    try:\n",
    "        m26 = pd.DataFrame.from_dict([nx.closeness_vitality(G)]).T\n",
    "\n",
    "    except:\n",
    "        m26 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m26.index = list(G.nodes)\n",
    "    m26.sort_index()\n",
    "    \n",
    "    try:\n",
    "        m27 = pd.DataFrame.from_dict([nx.trophic_levels(G)]).T\n",
    "\n",
    "    except:\n",
    "        m27 = pd.DataFrame([0 for i in range(len(G.nodes))])\n",
    "        m27.index = list(G.nodes)\n",
    "    m27.sort_index()\n",
    "    \n",
    "    final_df = pd.concat([m1, m2, m3, m4, m5, m6, m7, m8, m9, m10, m11, m12, m13, m14, m15, m16, m17, m18, m19,\n",
    "                         m20, m21, m22, m23, m24, m25, m26, m27], axis = 1)\n",
    "    final_df.columns = ['average_neighbor_degree',\n",
    "    'node_redundancy',\n",
    "    'degree_centrality',\n",
    "    'eigenvector_centrality',\n",
    "    'closeness_centrality',\n",
    "    'current_flow_closeness_centrality',\n",
    "    'information_centrality',\n",
    "    'betweenness_centrality',\n",
    "    'current_flow_betweenness_centrality',\n",
    "    'approximate_current_flow_betweenness_centrality',\n",
    "    'communicability_betweenness_centrality',\n",
    "    'subgraph_centrality',\n",
    "    'harmonic_centrality',\n",
    "    'second_order_centrality',\n",
    "    'voterank_importance',\n",
    "    'number_of_cliques',\n",
    "    'triangles',\n",
    "    'clustering',\n",
    "    'square_clustering',\n",
    "    'eccentricity',\n",
    "    'pagerank',\n",
    "    'hits_hub',\n",
    "    'hits_authority',\n",
    "    'constraint',\n",
    "    'effective_size',\n",
    "    'closeness_vitality',\n",
    "    'trophic_levels']\n",
    "    \n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22c074c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
